import requests
from bs4 import BeautifulSoup
import yfinance as yf
import os
import re
from datetime import datetime
import pytz

# --- ì„¤ì • êµ¬ê°„ ---
TOKEN = "8313563094:AAFiKFIwtpxdL7NhwmjhzQIqFItAxCeWY8U"
CHAT_ID = "868396866"
LAST_ID_FILE = "last_post_id.txt"

def is_market_open():
    """ì „ì¼ ë¯¸êµ­ ì‹œì¥ì´ ì—´ë ¸ì—ˆëŠ”ì§€ í™•ì¸ (íœ´ì¥ì¼ ë°œì†¡ ë°©ì§€)"""
    try:
        spy = yf.Ticker("^GSPC")
        hist = spy.history(period="1d")
        return not (hist.empty or hist['Volume'].iloc[-1] == 0)
    except:
        return False

def get_latest_link():
    """êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ì—ì„œ ìµœì‹  ì‹œí™© ì—…ë°ì´íŠ¸ ë§í¬ ì¶”ì¶œ"""
    search_url = "https://www.google.com/search?q=cnbc+stock+market+today+live+updates&tbm=nws"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        res = requests.get(search_url, headers=headers, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        for a in soup.select('a'):
            href = a.get('href', '')
            if 'cnbc.com' in href and 'live-updates' in href:
                match = re.search(r'(https?://www\.cnbc\.com/[^&]+)', href)
                if match: return match.group(1)
    except: pass
    return None

def translate_and_refine(text):
    """ë²ˆì—­ ë° ì¶œì²˜ ìˆ¨ê¸°ê¸° ë¬¸ì²´ ê°€ê³µ"""
    try:
        url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=ko&dt=t&q={text}"
        res = requests.get(url, timeout=10)
        full_text = "".join([s[0] for s in res.json()[0]])
        # CNBC ë° ê´€ë ¨ ë‹¨ì–´ë¥¼ ì¤‘ë¦½ì ì¸ í‘œí˜„ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ ì¶œì²˜ë¥¼ ìˆ¨ê¹€
        for word in ["CNBC", "ì”¨ì—”ë¹„ì”¨", "Live Updates", "ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"]:
            full_text = full_text.replace(word, "í˜„ì§€ ì‹œí™©íŒ€")
        return full_text.replace(". ", ".\n- ").strip()
    except: return text

def send_telegram(title, body):
    ko_title = translate_and_refine(title).split('\n')[0]
    ko_body = translate_and_refine(body)

    msg = f"ğŸ— **[ë°ì¼ë¦¬] ë¯¸ ì¦ì‹œ í•µì‹¬ ì‹œí™© ë¸Œë¦¬í•‘**\n"
    msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    msg += f"ğŸš© **í—¤ë“œë¼ì¸: {ko_title}**\n\n"
    msg += f"ğŸ“ **ìƒì„¸ ë¶„ì„:**\n- {ko_body}\n\n"
    msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    msg += f"âœ… ì‹œì¥ ë¶„ì„ ì—ì´ì „íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ"

    requests.post(f"https://api.telegram.org/bot{TOKEN}/sendMessage", 
                  data={"chat_id": CHAT_ID, "text": msg, "parse_mode": "Markdown"})

if __name__ == "__main__":
    # 1. íœ´ì¥ì¼ ì²´í¬
    if not is_market_open():
        print("ë¯¸êµ­ íœ´ì¥ì¼ì…ë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        exit()

    # 2. ìµœì‹  ë‰´ìŠ¤ íƒìƒ‰
    target_url = get_latest_link()
    if not target_url: exit()

    headers = {'User-Agent': 'Mozilla/5.0'}
    res = requests.get(target_url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    post = soup.select_one('.LiveBlog-post')

    if post:
        pid = post.get('id')
        last_id = ""
        if os.path.exists(LAST_ID_FILE):
            with open(LAST_ID_FILE, "r") as f: last_id = f.read().strip()

        # 3. ìƒˆë¡œìš´ ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì „ì†¡
        if pid != last_id:
            title = post.select_one('.LiveBlog-postTitle').get_text(strip=True) if post.select_one('.LiveBlog-postTitle') else "ì‹œì¥ ì£¼ìš” ì†Œì‹"
            content = post.select_one('.LiveBlog-postContent').get_text(strip=True) if post.select_one('.LiveBlog-postContent') else ""
            if content:
                send_telegram(title, content)
                with open(LAST_ID_FILE, "w") as f: f.write(pid)
