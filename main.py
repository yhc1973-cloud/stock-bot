import requests
from bs4 import BeautifulSoup
import re
import sys

# --- ì„¤ì • êµ¬ê°„ ---
TOKEN = "8313563094:AAFiKFIwtpxdL7NhwmjhzQIqFItAxCeWY8U"
CHAT_ID = "868396866"

def get_latest_link():
    """êµ¬ê¸€ ê²€ìƒ‰ì—ì„œ CNBC ë¼ì´ë¸Œ ë§í¬ë¥¼ ë” ì •ë°€í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ê²€ìƒ‰ì–´ì— 'today'ë¥¼ ë„£ì–´ ìµœì‹ ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    search_url = "https://www.google.com/search?q=cnbc+stock+market+today+live+updates&tbm=nws"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    }
    
    try:
        res = requests.get(search_url, headers=headers, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ëª¨ë“  ë§í¬ë¥¼ ë’¤ì ¸ì„œ cnbc ë¼ì´ë¸Œ ì—…ë°ì´íŠ¸ íŒ¨í„´ì„ ì°¾ìŠµë‹ˆë‹¤.
        links = soup.find_all('a', href=True)
        for a in links:
            href = a['href']
            # CNBC ê¸°ì‚¬ì´ê³  live-updatesê°€ í¬í•¨ëœ ì£¼ì†Œì¸ì§€ í™•ì¸
            if 'cnbc.com' in href and 'live-updates' in href:
                # êµ¬ê¸€ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì£¼ì†Œ(/url?q=...) ì²˜ë¦¬
                match = re.search(r'(https?://www\.cnbc\.com/[^&]+)', href)
                if match:
                    return match.group(1)
                elif href.startswith('http'):
                    return href
        
        print("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì ì ˆí•œ CNBC ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"êµ¬ê¸€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return None

def translate_and_refine(text):
    try:
        url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=ko&dt=t&q={text}"
        res = requests.get(url, timeout=10)
        full_text = "".join([s[0] for s in res.json()[0]])
        
        # ì¶œì²˜ ì–¸ê¸‰ ì§€ìš°ê¸°
        forbidden = ["CNBC", "ì”¨ì—”ë¹„ì”¨", "Live Updates", "ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"]
        for word in forbidden:
            full_text = full_text.replace(word, "í˜„ì§€ ì‹œí™©íŒ€")
        return full_text.replace(". ", ".\n- ").strip()
    except:
        return text

def send_telegram(title, body):
    ko_title = translate_and_refine(title).split('\n')[0]
    ko_body = translate_and_refine(body)

    msg = f"âš¡ï¸ **[ì‹¤ì‹œê°„] ë¯¸ ì¦ì‹œ ê¸´ê¸‰ ì‹œí™© ë¸Œë¦¬í•‘**\n"
    msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    msg += f"ğŸš© **ì£¼ìš” í—¤ë“œë¼ì¸: {ko_title}**\n\n"
    msg += f"ğŸ“ **ìƒì„¸ ë¶„ì„:**\n- {ko_body}\n\n"
    msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    msg += f"âœ… ì‹œìŠ¤í…œ ìë™ ì—…ë°ì´íŠ¸ ì™„ë£Œ"

    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    response = requests.post(url, data={
        "chat_id": CHAT_ID, 
        "text": msg, 
        "parse_mode": "Markdown"
    })
    
    if response.status_code == 200:
        print("í…”ë ˆê·¸ë¨ ì „ì†¡ ì„±ê³µ!")
    else:
        print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {response.text}")

if __name__ == "__main__":
    target_url = get_latest_link()
    
    if target_url:
        print(f"ìµœì‹  ë‰´ìŠ¤ ì ‘ì† ì£¼ì†Œ: {target_url}")
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(target_url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # CNBC ë¼ì´ë¸Œ ë¸”ë¡œê·¸ì˜ í¬ìŠ¤íŠ¸ êµ¬ì¡° í™•ì¸
        post = soup.select_one('.LiveBlog-post')
        
        if post:
            title_el = post.select_one('.LiveBlog-postTitle')
            content_el = post.select_one('.LiveBlog-postContent')
            
            title = title_el.get_text(strip=True) if title_el else "ì‹œì¥ ì£¼ìš” ì†Œì‹"
            content = content_el.get_text(strip=True) if content_el else ""
            
            if content:
                send_telegram(title, content)
            else:
                print("ê¸°ì‚¬ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("í•´ë‹¹ í˜ì´ì§€ì—ì„œ ë¼ì´ë¸Œ í¬ìŠ¤íŠ¸ í˜•ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("ëŒ€ìƒ URLì´ ì—†ì–´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
